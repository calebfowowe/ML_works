{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()"
   ],
   "id": "63a06ab1ea97216d",
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4abd7ea-ae74-489c-a8f8-809412513422",
   "metadata": {},
   "source": [
    "# Project Topic: Application of Blending Ensemble Learning in predicting positive moves (uptrend), a case-study on Nvidia Corporation stock price.\n",
    "### - Caleb Fowowe\n",
    "\n",
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "450f9a5f052c225",
   "metadata": {},
   "source": [
    "#Import the internal modules written for the purpose of this project\n",
    "from src.utils_data_processing import (LoadData, cwts, getpath, rnd_state)\n",
    "from src.utils_features_engineering import (FeaturesCreation, FeaturesTransformation, FeaturesSelection)\n",
    "from src.utils_model_and_tuning import (Blending, HpTuning, SimpleBacktest, Btest)\n",
    "\n",
    "#Import external modules for the basemodels and blender (metamodel)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#data manipulation modules\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Creates a folder for saving of code graphics and trading strategy report.\n",
    "output_path = getpath()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a289f098b02c4b5",
   "metadata": {},
   "source": [
    "### Load Data, EDA, Fix Null Data, and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eec8ce18aed3a6",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "id": "25281ee883e45473",
   "metadata": {},
   "source": [
    "#File names of the used data, provided as dictionary values.\n",
    "data_files = {'files': ['NVDA', 'VVIX_History', 'USCPI', 'USGDP', 'FedFundRate', '2yrTreasury', '10yrTreasury']} \n",
    "\n",
    "time_period = ['2008', '2024'] #specifies a period range, in the case provided data is goes back than required.\n",
    "company_name = data_files['files'][0] #Extract the company name or ticker into the company_name variable\n",
    "\n",
    "ldata = LoadData(*time_period, **data_files) #instantiate the class\n",
    "\n",
    "#Call the function to merger all the data into a single dataframe and returns the dataframe into variable 'df'\n",
    "df = ldata.joinData()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b1861c18dc7ee03",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cfe273e7e563c53f",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis (EDA) of Original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82026750e43c9a",
   "metadata": {},
   "source": [
    "##### Cleaning and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "id": "213b35de-3618-4c09-9def-401af22fa7ed",
   "metadata": {},
   "source": [
    "#Preview the original datasets of combined dataframe\n",
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e0fabece76b4de4",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ffc1388c4cb2857c",
   "metadata": {},
   "source": [
    "#Check for missing points and values within the combined dataset\n",
    "ldata.checkNullData(df)#within the ldata object, call the checkNullData method, with the df as input parameter"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36e97232603f621",
   "metadata": {},
   "source": [
    "#Intial step of fixing missing data, backfill the quarterly, and monthly macrodata,to \n",
    "df = ldata.fixNullData(df, method='bfill')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec75fac9acd70a82",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22a2faa481f4e900",
   "metadata": {},
   "source": [
    "#Post-backfilling check for null data after fixing null data\n",
    "ldata.checkNullData(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7764727d5ef8e80",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1bf26d910c20c0cc",
   "metadata": {},
   "source": [
    "#fix future data that are not available yet, can drop rows to choose, knn_impute method was used here.\n",
    "df = ldata.fixNullData(df, method='knnimpute')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45644fc4550fa81b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fd8c05af232fbd76",
   "metadata": {},
   "source": [
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c60a8da309bdf5ca",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94339d11a28df3c9",
   "metadata": {},
   "source": [
    "# preview the latest five (5) values of the cleaned up data\n",
    "df.tail()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4587167b5d559567",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b9af086b4bdbde3",
   "metadata": {},
   "source": [
    "# Plot candlestick of the historical stock data\n",
    "# stock_split = {'event_dates': ['2024-06-10', '2021-07-20', '2007-09-11', '2006-04-07', '2001-09-12', '2000-06-27'], 'event_title': 'stock-split'}\n",
    "stock_split = {'event_dates': ['2024-06-10', '2021-07-20'], 'event_title': 'stock-split'}\n",
    "ldata.plotCandleStick(df, events=stock_split)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15633d5393af61cf",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9b13bda9718610e",
   "metadata": {},
   "source": [
    "# plot individual (ohlcv)\n",
    "ldata.plotPrices(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "226fa80764d2a26b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f57f9a1d3f598a5d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bfe21c11ea24f4f7",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "##### FeaturesEngineering Class with the entire FeaturesCreation, FeaturesTransformation, and FeaturesSelections sub-classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6dd79d579a8fc9",
   "metadata": {},
   "source": [
    "#### Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c6383fb83643e",
   "metadata": {},
   "source": [
    "##### Define the parameters to be used in the target variable (y)/ Label"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f935138c82de30c",
   "metadata": {},
   "source": [
    "# The target variable is a trend and volatility play which creates a signal based on two conditions:\n",
    "# 1. when the return over a relative short period of time (5days i.e. mean of 5-day rolling return), \n",
    "# crosses over the return trend over a relative medium period (10days), with the difference been equal or \n",
    "# above a specified hurdle rate, (hurdle) the condition is deemed fulfilled. \n",
    "# 2. The other condition is a volatility play where the standard deviation of the short period return is less \n",
    "# or equal to the upper boundary standard deviation of the medium period return. The upper boundary of the medium\n",
    "# period returns standard deviation is characterized as 2-standard deviations from the mean medium_period return. \n",
    "\n",
    "# Target parameters\n",
    "short_prd= 5 \n",
    "medium_prd = 10\n",
    "upper_std=2 \n",
    "lower_std = 1 \n",
    "hurdle = 0.005"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8c79b379725478b1",
   "metadata": {},
   "source": [
    "##### Generate Features - all features"
   ]
  },
  {
   "cell_type": "code",
   "id": "b75aff6dcc13472d",
   "metadata": {},
   "source": [
    "# Instantiate the features creation subclass with the dataframe containing the cleaned data, alongside, the input\n",
    "#parameters for the target variable as input during class instantiation.\n",
    "\n",
    "#Instantiate the FeaturesCreation subclass providing the dataframe and the target parameters as inputs\n",
    "feat_df = FeaturesCreation(df, short_prd, medium_prd, upper_std, lower_std, hurdle) \n",
    "\n",
    "# Call the create_all_features method, setting the fundamental_features and macro_features parameters are true, if provided.\n",
    "# or false, otherwise. This should be linked to a variable in which an updated dataframe with all created features stored \n",
    "new_ft = feat_df.create_all_features(fundamental_features=True, macro_features=True) \n",
    "#1. Company fundamentals-related Features (Required column labels: 'PriceToEarnings', 'PriceToCash', 'PriceToBook', 'DividendYield')\n",
    "#2. Macroeconomic related features (Required column labels: 'CPI', 'GDP', '2yrTreasury', '10yrTreasury')\n",
    "#3. Technical Indicator features (based on pandas ta-library) (Required column label 'Open', 'High', 'Low', 'Close', 'Volume'\n",
    "# this can also be in lower case format)\n",
    "\n",
    "# The ohlcv columns are dropped after using them in the generation of the technical indicators. \n",
    "# Below is a preview of the first five row of the 339features including both, macroeconomic, fundamental and technical indicators.\n",
    "new_ft.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85771ee974f0ffb8",
   "metadata": {},
   "source": [
    "new_ft.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f74674138311228",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d56dc0b66c24a365",
   "metadata": {},
   "source": [
    "#### Feature Transformation & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc92bbfc51cf7a",
   "metadata": {},
   "source": [
    "##### Transform day of the week feature"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2477c5c6b8c2edf",
   "metadata": {},
   "source": [
    "# Prior to starting to features selection process, the days features which consist of trading days (Monday - Friday), is transformed, to two features.\n",
    "feat_transform = FeaturesTransformation(new_ft) #Instantiate the FeaturesTransformation subclass with generated features as input\n",
    "new_ft2 = feat_transform.transformDaysColumn() # Invoke the transformDaysColumn method, to transform the day of week column and store in new_ft2 variable"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf1e59968c3b6d0d",
   "metadata": {},
   "source": [
    "###### To optimize the dataframe performance, the all features outside the target column are convereted to 'float64', with the target variable column converted to 'int16' datatype"
   ]
  },
  {
   "cell_type": "code",
   "id": "204b9fd2ee98a458",
   "metadata": {},
   "source": [
    "new_ft2 = new_ft2.astype('float64')\n",
    "new_ft2['predict'] = new_ft2['predict'].values.astype('int16')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b42fd8e4064f228",
   "metadata": {},
   "source": [
    "new_ft2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14988e3172ea2fae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9f3ca6b353e7526",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb88883ed5a1e4",
   "metadata": {},
   "source": [
    "###### Feature selection - Wrapper Method: Boruta and Recursive Forward Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "id": "709bf88ca9060da4",
   "metadata": {},
   "source": [
    "#instantiate the FeaturesSelection subclass, providing dataframe from above, with the days column transformed \n",
    "# as required input parameters, and the testsize as an optional input parameter as well. Default testsize is 0.20.\n",
    "feat_select = FeaturesSelection(new_ft2, testsize = 0.20) \n",
    "feat1 = feat_select.wrapper_boruta(max_iter=150) # Call the wrapper_boruta method within the FeaturesSelection subclass."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c92d52365552218",
   "metadata": {},
   "source": [
    "##### Feature selection - Filtering Method: Addressing Multicollinearity among features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8020417f31f0882",
   "metadata": {},
   "source": [
    "###### using the same Feature Selection class, specify the correlation coefficient Threshold of choice. (The projected tested correlation in the 0.60 - 0.90) ranges."
   ]
  },
  {
   "cell_type": "code",
   "id": "f6550bd52e40e589",
   "metadata": {},
   "source": [
    "# Call the filter_correlation method, within the class providing it with the desired correlation threshold.\n",
    "# The multicollinearity steps follows the Boruta and RFE intersection steps. Hence, there is no need to specify the dataframe, the code has designed such that it already takes as input the dataframe which contains the features output of Boruta and RFE intersection. \n",
    "# However, for testing purposes, there's an optionality to provide the function with both correlation coefficient and dataframe, and it will filter for multicollinearitu among features.\n",
    "filtered_features = feat_select.filter_multicollinearity(corr_coeff=0.90)  "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bb0e75cf270d5f33",
   "metadata": {},
   "source": [
    "##### applying K-Means clustering to Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc0e1d8ba9b8eb8b",
   "metadata": {},
   "source": [
    "data2 = new_ft2[filtered_features]\n",
    "data2['predict'] = new_ft2['predict'].values.astype('int')\n",
    "\n",
    "kmeans_features = feat_select.kmeans_selector(data2, cluster_size=len(filtered_features), upper_threshold=0.065, lower_threshold=0.03) #upper threshold should at least be above the lower_threshold"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f87c0089ff90e05",
   "metadata": {},
   "source": [
    "##### Finally selected Features set - KMeans"
   ]
  },
  {
   "cell_type": "code",
   "id": "d188996d9e2035c7",
   "metadata": {},
   "source": [
    "data3 = new_ft2[kmeans_features]\n",
    "data3['predict'] = new_ft2['predict'].values.astype('int')\n",
    "\n",
    "data3.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29f4b6bc5b09bab7",
   "metadata": {},
   "source": [
    "data3.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90de5a72b777d63b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "749f9a56876c03bb",
   "metadata": {},
   "source": [
    "### Ensemble Model - Blending Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60167b724c42cc15",
   "metadata": {},
   "source": [
    "##### Initial parameterization of basemodels and metamodel"
   ]
  },
  {
   "cell_type": "code",
   "id": "ed3df1b4bdfea0e9",
   "metadata": {},
   "source": [
    "cls_weight = cwts(data3) #generate class weight to treat class imbalance\n",
    "\n",
    "# Logistic regression algorithm\n",
    "lr_params = {'random_state': rnd_state(), 'class_weight': cls_weight}\n",
    "lr = LogisticRegression(**lr_params)\n",
    "\n",
    "# Decision Tree algorithm\n",
    "dt_params = {'class_weight': cls_weight, 'random_state': rnd_state()}\n",
    "dt = DecisionTreeClassifier(**dt_params)\n",
    "\n",
    "# K-nearest Neighbour algorithm\n",
    "knn_params = {'algorithm': 'auto', 'n_jobs': -1}\n",
    "knn = KNeighborsClassifier(**knn_params)\n",
    "\n",
    "# Gaussian Naive Bayes algorithm \n",
    "bayes_params = {}\n",
    "bayes = GaussianNB()\n",
    "bayes.set_params(**bayes_params)\n",
    "\n",
    "# Support Vector Machine (SVM): Support Vector Classifier (SVC)\n",
    "svc_params = {'class_weight': cls_weight,'random_state': rnd_state(), 'probability': True}\n",
    "svc = SVC(**svc_params)\n",
    "\n",
    "# Combining all the algorithms into basemodels \n",
    "basemodels = {'lr': lr, 'dte': dt, 'knn': knn, 'bayes': bayes, 'svc': svc}\n",
    "\n",
    "# Extreme Gradient Boost algorithm\n",
    "xgb_params = {'n_jobs': -1, 'class_weight': cls_weight, 'random_state': rnd_state(), 'verbose': 1}\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "\n",
    "# Extreme gradient boosting stated as metamodel or blender.\n",
    "blender = xgb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b41db91f56f0b56b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae39b9e22fd7de04",
   "metadata": {},
   "source": [
    "##### Initial run of the blending model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d99066c02869beb7",
   "metadata": {},
   "source": [
    "#Separate final X and y - Features and target\n",
    "X_final = data3.iloc[:,:-1].values\n",
    "y_final = data3.iloc[:,-1].values\n",
    "\n",
    "Blnd = Blending(X_final, y_final, basemodels, blender, valsize=0.20)\n",
    "acc, f1score, ypred, yprob, yfull = Blnd.runBlendingEnsemble()\n",
    "\n",
    "print(f\"Accuracy Score: {acc: .1%}, f1score: {f1score:.1%}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a32afef0443b4782",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "id": "1eaafbac0e56f8c1",
   "metadata": {},
   "source": [
    "#Instantiate tuning\n",
    "tune_model = HpTuning(X_final, y_final, n_trials=40)\n",
    "tuned_lr, tuned_dt, tuned_svc, tuned_knn, tuned_bayes, tuned_xgb = tune_model.optimize_lr(), tune_model.optimize_dt(), tune_model.optimize_svc(), tune_model.optimize_knn(), tune_model.optimize_bayes(), tune_model.optimize_xgb()\n",
    "\n",
    "print(\"optimal_lr:\", tuned_lr.values, \"\\t\",\"optimal_dt:\", tuned_dt.values, \"\\t\", \"optimal_svc:\", tuned_svc.values, \"\\t\", \"optimal_knn:\", tuned_knn.values, \"\\t\", \"optimal_bayes:\", tuned_bayes.values, \"\\t\", \"optimal_xgb:\", tuned_xgb.values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1066c54-13f2-4992-b678-9996f4f3346b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "629a3cb6-a405-4497-b9d1-79c8a0fde436",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "96618945-46b6-4475-a57e-9b13149fd87e",
   "metadata": {},
   "source": [
    "##### Preview hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "55ea2822-df6b-427d-9c2b-5ef4c29048c0",
   "metadata": {},
   "source": [
    "hp_list = [tuned_lr.params, tuned_dt.params, tuned_svc.params, tuned_knn.params, tuned_bayes.params, tuned_xgb.params]\n",
    "hp_names = ['tuned_lr.params', 'tuned_dt.params', 'tuned_svc.params', 'tuned_knn.params', 'tuned_bayes.params', 'tuned_xgb.params']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71a0454b-495b-43bb-aad1-22cea6cc0358",
   "metadata": {},
   "source": [
    "tune_model.hp_preview(hp_list, hp_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec8491a3-59dc-48e5-9fab-1ed0405ff217",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f58e967bc9ef8",
   "metadata": {},
   "source": [
    "#### Run Ensemble Model with tuned parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e68814703af3f3",
   "metadata": {},
   "source": [
    "##### Update the initial parameters dictionary with the hyperparameter tuning parameter values"
   ]
  },
  {
   "cell_type": "code",
   "id": "daa10fc85132871",
   "metadata": {},
   "source": [
    "lr_params.update(tuned_lr.params)\n",
    "lr = LogisticRegression(**lr_params)\n",
    "\n",
    "dt_params.update(tuned_dt.params)\n",
    "dt = DecisionTreeClassifier(**dt_params)\n",
    "\n",
    "knn_params.update(tuned_knn.params)\n",
    "knn = KNeighborsClassifier(**knn_params)\n",
    "\n",
    "bayes = GaussianNB()\n",
    "bayes.set_params(**bayes_params)\n",
    "\n",
    "svc_params.update(tuned_svc.params)\n",
    "svc = SVC(**svc_params)\n",
    "\n",
    "basemodel_upd = {'lre': lr, 'dte': dt, 'knn': knn, 'bayes': bayes, 'svc': svc}\n",
    "\n",
    "xgb_params.update(tuned_xgb.params)\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "\n",
    "blender_upd = xgb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26c9fd52d3760c2d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a95dc111207d52a6",
   "metadata": {},
   "source": [
    "##### TunedModels Output"
   ]
  },
  {
   "cell_type": "code",
   "id": "c205e3f2658457bb",
   "metadata": {},
   "source": [
    "Blnd = Blending(X_final, y_final, basemodel_upd, blender_upd, valsize=0.20)\n",
    "acc_tuned, f1score_tuned, ypred_tuned, yprob_tuned, yfull_tuned = Blnd.runBlendingEnsemble()\n",
    "\n",
    "print(f\"Accuracy Score: {acc_tuned: .1%}, f1score: {f1score_tuned:.1%}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4489b142a65b0c9c",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6f6a7bdf8131e8ae",
   "metadata": {},
   "source": [
    "### Backtest/Strategy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a553977b9644e9d",
   "metadata": {},
   "source": [
    "#### Approach 1: Using the simple backtest class - Out of sample test"
   ]
  },
  {
   "cell_type": "code",
   "id": "c24317568f52eb7b",
   "metadata": {},
   "source": [
    "return_period = 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f9a2556f049aa30",
   "metadata": {},
   "source": [
    "btd = SimpleBacktest(df)\n",
    "btdd = btd.approach1(ypred, return_period)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4863036f50e19717",
   "metadata": {},
   "source": [
    "sharpe2 = btd.sharpe_ratios(btdd)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0dcc5186684a3b",
   "metadata": {},
   "source": [
    "btd.html_report(company_name=company_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d27b4ee3d0fb7a1",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27b9a443c75131c1",
   "metadata": {},
   "source": [
    "#### Approach 2: Using the popular Backtesting Library - Out of Sample test"
   ]
  },
  {
   "cell_type": "code",
   "id": "594d52fd-5db6-4b9f-91cb-ad033d991244",
   "metadata": {},
   "source": [
    "bto_lib = Btest(df, ypred)\n",
    "bto_lib.runStrategy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f9350f1-872c-4ed5-8ff7-8a56453882b0",
   "metadata": {},
   "source": [
    "btostats = bto_lib.runstats()\n",
    "print(btostats)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b98a4ee-00cd-427c-9976-513827fe081f",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7a4ed13-6d12-4b3e-8fa3-5f8056272d58",
   "metadata": {},
   "source": [
    "bto_lib.plotstats()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6eb331d7-8e50-4e29-b07c-3046e0517d2e",
   "metadata": {},
   "source": "t2 = time.time()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c18e988de830f",
   "metadata": {},
   "source": "print(f\"Time-taken to run entire script is: {t2-t1:.2f} seconds\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "771081fcb07ab64a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
